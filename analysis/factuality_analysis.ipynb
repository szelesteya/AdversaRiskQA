{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95821400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "import json\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4152f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>domain</th>\n",
       "      <th>level</th>\n",
       "      <th>evaluation_type</th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>number_of_facts</th>\n",
       "      <th>correct_facts</th>\n",
       "      <th>question_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>finance_advanced_adv</td>\n",
       "      <td>finance</td>\n",
       "      <td>advanced</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>How can multiple IRRs distort a go/no-go decis...</td>\n",
       "      <td>Answer in 5 sentences or less.\\n\\nMultiple IRR...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finance_advanced_adv</td>\n",
       "      <td>finance</td>\n",
       "      <td>advanced</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>Where can a payback rule cause management to r...</td>\n",
       "      <td>The statement is false because the payback per...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>finance_advanced_adv</td>\n",
       "      <td>finance</td>\n",
       "      <td>advanced</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>How do post-earnings announcement drifts chall...</td>\n",
       "      <td>Answer in 5 sentences or less.\\n\\nPost-earning...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finance_advanced_adv</td>\n",
       "      <td>finance</td>\n",
       "      <td>advanced</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>How robust is beta estimation for thinly trade...</td>\n",
       "      <td>Hmm, there's a misunderstanding in your questi...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>finance_advanced_adv</td>\n",
       "      <td>finance</td>\n",
       "      <td>advanced</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>When does leverage mask deteriorating core pro...</td>\n",
       "      <td>Okay, the user is asking about when leverage c...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dataset   domain     level evaluation_type  \\\n",
       "0  finance_advanced_adv  finance  advanced     adversarial   \n",
       "1  finance_advanced_adv  finance  advanced     adversarial   \n",
       "2  finance_advanced_adv  finance  advanced     adversarial   \n",
       "3  finance_advanced_adv  finance  advanced     adversarial   \n",
       "4  finance_advanced_adv  finance  advanced     adversarial   \n",
       "\n",
       "                                               query  \\\n",
       "0  How can multiple IRRs distort a go/no-go decis...   \n",
       "1  Where can a payback rule cause management to r...   \n",
       "2  How do post-earnings announcement drifts chall...   \n",
       "3  How robust is beta estimation for thinly trade...   \n",
       "4  When does leverage mask deteriorating core pro...   \n",
       "\n",
       "                                              answer  number_of_facts  \\\n",
       "0  Answer in 5 sentences or less.\\n\\nMultiple IRR...                6   \n",
       "1  The statement is false because the payback per...                6   \n",
       "2  Answer in 5 sentences or less.\\n\\nPost-earning...                6   \n",
       "3  Hmm, there's a misunderstanding in your questi...               10   \n",
       "4  Okay, the user is asking about when leverage c...                7   \n",
       "\n",
       "   correct_facts  question_number  \n",
       "0              6                1  \n",
       "1              5                2  \n",
       "2              5                3  \n",
       "3             10                4  \n",
       "4              7                5  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _load_evaluated_results(file_path: Path) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Load evaluated results (with factuality) from a JSON file.\"\"\"\n",
    "    with file_path.open(\"r\", encoding=\"utf-8\") as file:\n",
    "        payload: Dict[str, Any] = json.load(file)\n",
    "    return payload.get(\"results\", []) or []\n",
    "\n",
    "\n",
    "def _parse_dataset_name(dataset_name: str) -> Dict[str, str]:\n",
    "    \"\"\"Parse dataset name to extract domain, level, and evaluation type.\n",
    "    \n",
    "    Expected format: {domain}_{level}_{type}\n",
    "    Examples: finance_advanced_adv, health_basic_non_adv, law_advanced_adv\n",
    "    \"\"\"\n",
    "    parts: List[str] = dataset_name.split(\"_\")\n",
    "    \n",
    "    # Determine domain (first part)\n",
    "    domain: str = parts[0] if len(parts) > 0 else \"unknown\"\n",
    "    \n",
    "    # Determine level (second part)\n",
    "    level: str = parts[1] if len(parts) > 1 else \"unknown\"\n",
    "    \n",
    "    # Determine evaluation type (last part or last two parts)\n",
    "    # Handle both \"_adv\" and \"_non_adv\" endings\n",
    "    if len(parts) >= 3:\n",
    "        if parts[-2] == \"non\" and parts[-1] == \"adv\":\n",
    "            eval_type: str = \"non_adversarial\"\n",
    "        elif parts[-1] == \"adv\":\n",
    "            eval_type: str = \"adversarial\"\n",
    "        else:\n",
    "            eval_type: str = \"unknown\"\n",
    "    else:\n",
    "        eval_type: str = \"unknown\"\n",
    "    \n",
    "    return {\n",
    "        \"domain\": domain,\n",
    "        \"level\": level,\n",
    "        \"evaluation_type\": eval_type,\n",
    "    }\n",
    "\n",
    "\n",
    "def build_factuality_dataframe(results_dir: Path) -> pd.DataFrame:\n",
    "    \"\"\"Build a dataframe with query, answer, number_of_facts, correct_facts, question_number.\n",
    "\n",
    "    This aggregates all evaluated factuality results from the given directory.\n",
    "    \"\"\"\n",
    "    records: List[Dict[str, Any]] = []\n",
    "\n",
    "    json_files: List[Path] = sorted(\n",
    "        [\n",
    "            path\n",
    "            for path in results_dir.iterdir()\n",
    "            if path.suffix == \".json\" and (path.name.endswith(\"_adv.json\") or path.name.endswith(\"_non_adv.json\")) and \"golden\" not in path.name\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    question_counter: int = 1\n",
    "    for json_file in json_files:\n",
    "        dataset_name: str = json_file.stem\n",
    "        parsed_dataset: Dict[str, str] = _parse_dataset_name(dataset_name)\n",
    "        results = _load_evaluated_results(json_file)\n",
    "        for _index, item in enumerate(results, start=1):\n",
    "            factuality: Dict[str, Any] = item.get(\"factuality\") or {}\n",
    "            facts: List[str] = factuality.get(\"facts\") or []\n",
    "            fact_check: Dict[str, Any] = factuality.get(\"fact_check\") or {}\n",
    "            decisions: List[Dict[str, Any]] = fact_check.get(\"decisions\") or []\n",
    "\n",
    "            correct_count: int = sum(1 for decision in decisions if decision.get(\"correct\") is True)\n",
    "\n",
    "            response: Dict[str, Any] = item.get(\"response\") or {}\n",
    "\n",
    "            records.append(\n",
    "                {\n",
    "                    \"dataset\": dataset_name,\n",
    "                    \"domain\": parsed_dataset[\"domain\"],\n",
    "                    \"level\": parsed_dataset[\"level\"],\n",
    "                    \"evaluation_type\": parsed_dataset[\"evaluation_type\"],\n",
    "                    \"query\": item.get(\"query\") or item.get(\"question\"),\n",
    "                    \"answer\": factuality.get(\"answer\") or response.get(\"answer\"),\n",
    "                    \"number_of_facts\": len(facts),\n",
    "                    \"correct_facts\": correct_count,\n",
    "                    \"question_number\": question_counter,\n",
    "                }\n",
    "            )\n",
    "            question_counter += 1\n",
    "\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "\n",
    "# Load results from both adversarial and non-adversarial directories\n",
    "adversarial_directory: Path = Path(\n",
    "    \"/Users/aszelestey/projects/AdversaRiskQA/data/results/factuality_evaluations/adversarial/Qwen-Qwen3-30B-Instruct-2507\"\n",
    ")\n",
    "non_adversarial_directory: Path = Path(\n",
    "    \"/Users/aszelestey/projects/AdversaRiskQA/data/results/factuality_evaluations/non_adversial/Qwen-Qwen3-30B-Instruct-2507\"\n",
    ")\n",
    "\n",
    "# Build dataframes from both directories\n",
    "adversarial_df: pd.DataFrame = build_factuality_dataframe(adversarial_directory)\n",
    "non_adversarial_df: pd.DataFrame = build_factuality_dataframe(non_adversarial_directory)\n",
    "\n",
    "# Combine both dataframes\n",
    "factuality_df: pd.DataFrame = pd.concat([adversarial_df, non_adversarial_df], ignore_index=True)\n",
    "\n",
    "factuality_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee8b6e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median number_of_facts: 8.0\n"
     ]
    }
   ],
   "source": [
    "median_facts = factuality_df[\"number_of_facts\"].median()\n",
    "print(\"Median number_of_facts:\", median_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3bd303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using K= 8\n",
      "Mean F_1@K: 0.8069702294542597\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>domain</th>\n",
       "      <th>level</th>\n",
       "      <th>evaluation_type</th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>number_of_facts</th>\n",
       "      <th>correct_facts</th>\n",
       "      <th>question_number</th>\n",
       "      <th>F1_at_K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>finance_advanced_adv</td>\n",
       "      <td>finance</td>\n",
       "      <td>advanced</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>How can multiple IRRs distort a go/no-go decis...</td>\n",
       "      <td>Answer in 5 sentences or less.\\n\\nMultiple IRR...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finance_advanced_adv</td>\n",
       "      <td>finance</td>\n",
       "      <td>advanced</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>Where can a payback rule cause management to r...</td>\n",
       "      <td>The statement is false because the payback per...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>finance_advanced_adv</td>\n",
       "      <td>finance</td>\n",
       "      <td>advanced</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>How do post-earnings announcement drifts chall...</td>\n",
       "      <td>Answer in 5 sentences or less.\\n\\nPost-earning...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finance_advanced_adv</td>\n",
       "      <td>finance</td>\n",
       "      <td>advanced</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>How robust is beta estimation for thinly trade...</td>\n",
       "      <td>Hmm, there's a misunderstanding in your questi...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>finance_advanced_adv</td>\n",
       "      <td>finance</td>\n",
       "      <td>advanced</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>When does leverage mask deteriorating core pro...</td>\n",
       "      <td>Okay, the user is asking about when leverage c...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dataset   domain     level evaluation_type  \\\n",
       "0  finance_advanced_adv  finance  advanced     adversarial   \n",
       "1  finance_advanced_adv  finance  advanced     adversarial   \n",
       "2  finance_advanced_adv  finance  advanced     adversarial   \n",
       "3  finance_advanced_adv  finance  advanced     adversarial   \n",
       "4  finance_advanced_adv  finance  advanced     adversarial   \n",
       "\n",
       "                                               query  \\\n",
       "0  How can multiple IRRs distort a go/no-go decis...   \n",
       "1  Where can a payback rule cause management to r...   \n",
       "2  How do post-earnings announcement drifts chall...   \n",
       "3  How robust is beta estimation for thinly trade...   \n",
       "4  When does leverage mask deteriorating core pro...   \n",
       "\n",
       "                                              answer  number_of_facts  \\\n",
       "0  Answer in 5 sentences or less.\\n\\nMultiple IRR...                6   \n",
       "1  The statement is false because the payback per...                6   \n",
       "2  Answer in 5 sentences or less.\\n\\nPost-earning...                6   \n",
       "3  Hmm, there's a misunderstanding in your questi...               10   \n",
       "4  Okay, the user is asking about when leverage c...                7   \n",
       "\n",
       "   correct_facts  question_number   F1_at_K  \n",
       "0              6                1  0.857143  \n",
       "1              5                2  0.714286  \n",
       "2              5                3  0.714286  \n",
       "3             10                4  1.000000  \n",
       "4              7                5  0.933333  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def _compute_precision(supported_facts: int, total_facts: int) -> float:\n",
    "    \"\"\"Compute factual precision Prec(y) = S(y) / (S(y) + N(y)).\"\"\"\n",
    "    if total_facts <= 0:\n",
    "        return 0.0\n",
    "    return supported_facts / float(total_facts)\n",
    "\n",
    "\n",
    "def _compute_recall_at_k(supported_facts: int, k: int) -> float:\n",
    "    \"\"\"Compute factual recall R_K(y) = min(S(y) / K, 1).\"\"\"\n",
    "    if k <= 0:\n",
    "        raise ValueError(\"K must be a positive integer.\")\n",
    "    return min(supported_facts / float(k), 1.0)\n",
    "\n",
    "\n",
    "def _compute_f1_at_k_for_row(row: pd.Series, k: int) -> float:  # type: ignore[type-arg]\n",
    "    \"\"\"Compute F_1@K for a single dataframe row.\"\"\"\n",
    "    supported_facts: int = int(row[\"correct_facts\"])\n",
    "    total_facts: int = int(row[\"number_of_facts\"])\n",
    "\n",
    "    if supported_facts <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    precision: float = _compute_precision(supported_facts=supported_facts, total_facts=total_facts)\n",
    "    recall_k: float = _compute_recall_at_k(supported_facts=supported_facts, k=k)\n",
    "\n",
    "    if precision + recall_k == 0.0:\n",
    "        return 0.0\n",
    "\n",
    "    return 2.0 * precision * recall_k / (precision + recall_k)\n",
    "\n",
    "\n",
    "def compute_f1_at_k_for_dataframe(df: pd.DataFrame, k: int) -> Tuple[pd.DataFrame, float]:\n",
    "    \"\"\"Return a copy of the dataframe with F_1@K column and its mean value.\n",
    "\n",
    "    Args:\n",
    "        df: Input dataframe with `number_of_facts` and `correct_facts` columns.\n",
    "        k: Hyperparameter K from the SAFE definition.\n",
    "    \"\"\"\n",
    "    df_with_f1 = df.copy()\n",
    "    df_with_f1[\"F1_at_K\"] = df_with_f1.apply(_compute_f1_at_k_for_row, axis=1, k=k)\n",
    "    mean_f1_at_k: float = float(df_with_f1[\"F1_at_K\"].mean())\n",
    "    return df_with_f1, mean_f1_at_k\n",
    "\n",
    "\n",
    "K: int = int(median_facts)\n",
    "\n",
    "factuality_df_with_f1, mean_f1_at_k = compute_f1_at_k_for_dataframe(factuality_df, k=K)\n",
    "\n",
    "print(\"Using K=\", K)\n",
    "print(\"Mean F_1@K:\", mean_f1_at_k)\n",
    "\n",
    "factuality_df_with_f1[factuality_df_with_f1[\"dataset\"] == \"non\"].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de94d8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>level</th>\n",
       "      <th>evaluation_type</th>\n",
       "      <th>mean_F1_at_K</th>\n",
       "      <th>mean_number_of_facts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>finance</td>\n",
       "      <td>advanced</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>0.842473</td>\n",
       "      <td>8.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finance</td>\n",
       "      <td>basic</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>0.781781</td>\n",
       "      <td>7.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>health</td>\n",
       "      <td>advanced</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>0.810276</td>\n",
       "      <td>8.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>health</td>\n",
       "      <td>basic</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>0.859827</td>\n",
       "      <td>9.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>law</td>\n",
       "      <td>advanced</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>0.770403</td>\n",
       "      <td>7.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>law</td>\n",
       "      <td>basic</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>0.720898</td>\n",
       "      <td>7.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    domain     level evaluation_type  mean_F1_at_K  mean_number_of_facts\n",
       "0  finance  advanced     adversarial      0.842473                  8.16\n",
       "1  finance     basic     adversarial      0.781781                  7.10\n",
       "2   health  advanced     adversarial      0.810276                  8.43\n",
       "3   health     basic     adversarial      0.859827                  9.09\n",
       "4      law  advanced     adversarial      0.770403                  7.86\n",
       "5      law     basic     adversarial      0.720898                  7.03"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict as TypingDict\n",
    "\n",
    "\n",
    "def aggregate_f1_by_dataset(df_with_f1: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Aggregate F_1@K scores and mean number_of_facts per dataset.\n",
    "\n",
    "    Returns a dataframe with one row per dataset containing:\n",
    "    - mean_F1_at_K\n",
    "    - mean_number_of_facts\n",
    "    \"\"\"\n",
    "    grouped = (\n",
    "        df_with_f1.groupby([\"domain\", \"level\", \"evaluation_type\"], as_index=False)[[\"F1_at_K\", \"number_of_facts\"]]\n",
    "        .mean()\n",
    "        .rename(columns={\"F1_at_K\": \"mean_F1_at_K\", \"number_of_facts\": \"mean_number_of_facts\"})\n",
    "    )\n",
    "    return grouped\n",
    "\n",
    "\n",
    "per_dataset_f1: pd.DataFrame = aggregate_f1_by_dataset(factuality_df_with_f1)\n",
    "\n",
    "per_dataset_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "208f69b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-dataset median number_of_facts:\n",
      "dataset\n",
      "finance_advanced_adv        8.0\n",
      "finance_advanced_non_adv    7.0\n",
      "finance_basic_adv           6.0\n",
      "finance_basic_non_adv       6.5\n",
      "health_advanced_adv         8.0\n",
      "health_advanced_non_adv     9.5\n",
      "health_basic_adv            8.5\n",
      "health_basic_non_adv        9.5\n",
      "law_advanced_adv            8.0\n",
      "law_advanced_non_adv        8.0\n",
      "law_basic_adv               8.0\n",
      "law_basic_non_adv           6.5\n",
      "Name: number_of_facts, dtype: float64\n",
      "Using K (median over dataset medians) = 8\n",
      "Mean F_1@K with this K: 0.8069702294542597\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>level</th>\n",
       "      <th>evaluation_type</th>\n",
       "      <th>mean_F1_at_K</th>\n",
       "      <th>mean_number_of_facts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>finance</td>\n",
       "      <td>advanced</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>0.842473</td>\n",
       "      <td>8.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finance</td>\n",
       "      <td>basic</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>0.781781</td>\n",
       "      <td>7.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>health</td>\n",
       "      <td>advanced</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>0.810276</td>\n",
       "      <td>8.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>health</td>\n",
       "      <td>basic</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>0.859827</td>\n",
       "      <td>9.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>law</td>\n",
       "      <td>advanced</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>0.770403</td>\n",
       "      <td>7.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>law</td>\n",
       "      <td>basic</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>0.720898</td>\n",
       "      <td>7.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    domain     level evaluation_type  mean_F1_at_K  mean_number_of_facts\n",
       "0  finance  advanced     adversarial      0.842473                  8.16\n",
       "1  finance     basic     adversarial      0.781781                  7.10\n",
       "2   health  advanced     adversarial      0.810276                  8.43\n",
       "3   health     basic     adversarial      0.859827                  9.09\n",
       "4      law  advanced     adversarial      0.770403                  7.86\n",
       "5      law     basic     adversarial      0.720898                  7.03"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute K as the median of per-dataset median number_of_facts\n",
    "\n",
    "per_dataset_median_facts = factuality_df.groupby(\"dataset\")[\"number_of_facts\"].median()\n",
    "K_from_datasets: int = int(per_dataset_median_facts.median())\n",
    "\n",
    "factuality_df_with_f1_datasetK, mean_f1_at_k_datasetK = compute_f1_at_k_for_dataframe(\n",
    "    factuality_df, k=K_from_datasets\n",
    ")\n",
    "\n",
    "print(\"Per-dataset median number_of_facts:\")\n",
    "print(per_dataset_median_facts)\n",
    "print(\"Using K (median over dataset medians) =\", K_from_datasets)\n",
    "print(\"Mean F_1@K with this K:\", mean_f1_at_k_datasetK)\n",
    "\n",
    "per_dataset_f1_datasetK: pd.DataFrame = aggregate_f1_by_dataset(factuality_df_with_f1_datasetK)\n",
    "\n",
    "per_dataset_f1_datasetK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b137ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
