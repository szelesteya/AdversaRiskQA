{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15b95ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc4f97e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "from pathlib import Path\n",
    "from common.modeling import Model\n",
    "from eval.safe.query_serper import SerperAPI\n",
    "from eval.safe.search_augmented_factuality_eval import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c3db1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(model_name=\"OPENAI:gpt-4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0658531",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 25] Inappropriate ioctl for device",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AdversaRiskQA/eval/safe/search_augmented_factuality_eval.py:156\u001b[39m, in \u001b[36mclassify_relevance_and_rate\u001b[39m\u001b[34m(prompt, response, sentences_and_atomic_facts, rater)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    155\u001b[39m   checked_statement, revised_fact_dict, past_steps_dict = (\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m       \u001b[43mclassify_relevance_and_rate_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m          \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m          \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m          \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m=\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m          \u001b[49m\u001b[43matomic_fact\u001b[49m\u001b[43m=\u001b[49m\u001b[43matomic_fact\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m          \u001b[49m\u001b[43mrater\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrater\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m   )\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-exception-caught\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AdversaRiskQA/eval/safe/search_augmented_factuality_eval.py:116\u001b[39m, in \u001b[36mclassify_relevance_and_rate_single\u001b[39m\u001b[34m(prompt, response, sentence, atomic_fact, rater)\u001b[39m\n\u001b[32m    114\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m checked_statement, revised_fact_dict, {}\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m rate_data, past_steps_dict = \u001b[43mrate_atomic_fact\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck_atomic_fact\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43matomic_fact\u001b[49m\u001b[43m=\u001b[49m\u001b[43mself_contained_atomic_fact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrater\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrater\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rate_data, rate_atomic_fact.FinalAnswer):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AdversaRiskQA/eval/safe/rate_atomic_fact.py:162\u001b[39m, in \u001b[36mcheck_atomic_fact\u001b[39m\u001b[34m(atomic_fact, rater, max_steps, max_retries, debug)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m next_search \u001b[38;5;129;01mand\u001b[39;00m num_tries <= max_retries:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m   next_search = \u001b[43mmaybe_get_next_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43matomic_fact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrater\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m   num_tries += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AdversaRiskQA/eval/safe/rate_atomic_fact.py:120\u001b[39m, in \u001b[36mmaybe_get_next_search\u001b[39m\u001b[34m(atomic_fact, past_searches, model, debug)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_response \u001b[38;5;129;01mand\u001b[39;00m query:\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m GoogleSearchResult(query=query, result=\u001b[43mcall_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AdversaRiskQA/eval/safe/rate_atomic_fact.py:99\u001b[39m, in \u001b[36mcall_search\u001b[39m\u001b[34m(search_query, search_type, num_searches, serper_api_key, search_postamble)\u001b[39m\n\u001b[32m     98\u001b[39m   serper_searcher = query_serper.SerperAPI(serper_api_key, k=num_searches)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserper_searcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_searches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AdversaRiskQA/eval/safe/query_serper.py:64\u001b[39m, in \u001b[36mSerperAPI.run\u001b[39m\u001b[34m(self, query, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m results = \u001b[38;5;28mself\u001b[39m._google_serper_api_results(\n\u001b[32m     55\u001b[39m     query,\n\u001b[32m     56\u001b[39m     gl=\u001b[38;5;28mself\u001b[39m.gl,\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m     **kwargs,\n\u001b[32m     62\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AdversaRiskQA/eval/safe/query_serper.py:153\u001b[39m, in \u001b[36mSerperAPI._parse_results\u001b[39m\u001b[34m(self, results)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_parse_results\u001b[39m(\u001b[38;5;28mself\u001b[39m, results: \u001b[38;5;28mdict\u001b[39m[Any, Any]) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33;43m'\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_snippets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: sequence item 1: expected str instance, list found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m question = results[\u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      5\u001b[39m answer = results[\u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m evaluation = \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrater\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AdversaRiskQA/eval/safe/search_augmented_factuality_eval.py:184\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(prompt, response, rater)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m(prompt: \u001b[38;5;28mstr\u001b[39m, response: \u001b[38;5;28mstr\u001b[39m, rater: modeling.Model) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    183\u001b[39m   atomic_facts = get_atomic_facts.main(response=response, model=rater)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m   rating_result = \u001b[43mclassify_relevance_and_rate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m      \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m      \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m      \u001b[49m\u001b[43msentences_and_atomic_facts\u001b[49m\u001b[43m=\u001b[49m\u001b[43matomic_facts\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mall_atomic_facts\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m      \u001b[49m\u001b[43mrater\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrater\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    190\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    191\u001b[39m       \u001b[33m'\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m'\u001b[39m: prompt, \u001b[33m'\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m'\u001b[39m: response, **atomic_facts, **rating_result\n\u001b[32m    192\u001b[39m   }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AdversaRiskQA/eval/safe/search_augmented_factuality_eval.py:165\u001b[39m, in \u001b[36mclassify_relevance_and_rate\u001b[39m\u001b[34m(prompt, response, sentences_and_atomic_facts, rater)\u001b[39m\n\u001b[32m    155\u001b[39m   checked_statement, revised_fact_dict, past_steps_dict = (\n\u001b[32m    156\u001b[39m       classify_relevance_and_rate_single(\n\u001b[32m    157\u001b[39m           prompt=prompt,\n\u001b[32m   (...)\u001b[39m\u001b[32m    162\u001b[39m       )\n\u001b[32m    163\u001b[39m   )\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-exception-caught\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m   \u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaybe_print_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m   checked_statement, revised_fact_dict, past_steps_dict = \u001b[38;5;28;01mNone\u001b[39;00m, {}, {}\n\u001b[32m    167\u001b[39m   num_fails += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AdversaRiskQA/common/utils.py:240\u001b[39m, in \u001b[36mmaybe_print_error\u001b[39m\u001b[34m(message, additional_info, verbose)\u001b[39m\n\u001b[32m    238\u001b[39m message = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(message)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    239\u001b[39m message += \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00madditional_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[43mclear_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m print_color(message, color=\u001b[33m'\u001b[39m\u001b[33mred\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AdversaRiskQA/common/utils.py:195\u001b[39m, in \u001b[36mclear_line\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclear_line\u001b[39m() -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    194\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Clears the current line.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m   \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m * \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_terminal_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.columns, end=\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: [Errno 25] Inappropriate ioctl for device"
     ]
    }
   ],
   "source": [
    "with open(Path(\"Qwen-Qwen3-Next-80B-A3B-Instruct-finance_basic_golden.json\"), \"r\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "question = results[\"results\"][0][\"query\"]\n",
    "answer = results[\"results\"][0][\"response\"][\"answer\"]\n",
    "\n",
    "evaluation = main(question, answer, rater=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d7b3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
